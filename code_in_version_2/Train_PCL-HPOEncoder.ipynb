{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "44460eda",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/envs/HT2VEC/envs/PhenoDP/lib/python3.7/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from pyhpo import Ontology\n",
    "from PCL_HPOEncoder import *\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "import random\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f053187d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyhpo.ontology.OntologyClass at 0x7f5189122518>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "Ontology('./HPO_2025_3_3/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ac2cccd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open('./node_embedding_dict_test.plk', 'rb') as f:\n",
    "    node_embedding = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d586a2fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "disease_dict = dict()\n",
    "disease_list = list(Ontology.omim_diseases)\n",
    "hps_list = (node_embedding.keys())\n",
    "for d in disease_list:\n",
    "    disease_dict[d.id] = [Ontology.get_hpo_object(t).id for t in list(d.hpo) if Ontology.get_hpo_object(t).id in hps_list]\n",
    "\n",
    "d_count = []\n",
    "disease_db = []\n",
    "for i in list(disease_dict.keys()):\n",
    "    if len(disease_dict[i]) >= 5:\n",
    "        disease_db.append(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "35b09df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "input_dim = 256\n",
    "num_heads = 8\n",
    "num_layers = 3\n",
    "hidden_dim = 512\n",
    "output_dim = 1\n",
    "max_seq_length = 128\n",
    "\n",
    "model = PCL_HPOEncoder(input_dim, num_heads, num_layers, hidden_dim, output_dim, max_seq_length)\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f96028e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 4.627202296257019\n",
      "Epoch 2, Loss: 4.240150046348572\n",
      "Epoch 3, Loss: 3.989004373550415\n",
      "Epoch 4, Loss: 3.7461729288101195\n",
      "Epoch 5, Loss: 3.5224256038665773\n",
      "Epoch 6, Loss: 3.333056557178497\n",
      "Epoch 7, Loss: 3.1676364183425902\n",
      "Epoch 8, Loss: 2.9961713194847106\n",
      "Epoch 9, Loss: 2.8208709239959715\n",
      "Epoch 10, Loss: 2.6738101482391357\n",
      "Epoch 11, Loss: 2.51875821352005\n",
      "Epoch 12, Loss: 2.390128219127655\n",
      "Epoch 13, Loss: 2.2942910194396973\n",
      "Epoch 14, Loss: 2.1770077109336854\n",
      "Epoch 15, Loss: 2.0273988127708433\n",
      "Epoch 16, Loss: 1.9442080080509185\n",
      "Epoch 17, Loss: 1.8290502667427062\n",
      "Epoch 18, Loss: 1.7930613100528716\n",
      "Epoch 19, Loss: 1.7642766654491424\n",
      "Epoch 20, Loss: 1.6556639671325684\n",
      "Epoch 21, Loss: 1.588652390241623\n",
      "Epoch 22, Loss: 1.518041294813156\n",
      "Epoch 23, Loss: 1.476681661605835\n",
      "Epoch 24, Loss: 1.4305603206157684\n",
      "Epoch 25, Loss: 1.3992465555667877\n",
      "Epoch 26, Loss: 1.4107238173484802\n",
      "Epoch 27, Loss: 1.3659060537815093\n",
      "Epoch 28, Loss: 1.3196948409080504\n",
      "Epoch 29, Loss: 1.2966501116752625\n",
      "Epoch 30, Loss: 1.2675913989543914\n",
      "Epoch 31, Loss: 1.2475154519081115\n",
      "Epoch 32, Loss: 1.2461741805076598\n",
      "Epoch 33, Loss: 1.2227506458759307\n",
      "Epoch 34, Loss: 1.1915965795516967\n",
      "Epoch 35, Loss: 1.1809971928596497\n",
      "Epoch 36, Loss: 1.176004809141159\n",
      "Epoch 37, Loss: 1.165790742635727\n",
      "Epoch 38, Loss: 1.1456194519996643\n",
      "Epoch 39, Loss: 1.1288836300373077\n",
      "Epoch 40, Loss: 1.1163224756717682\n",
      "Epoch 41, Loss: 1.1080419719219208\n",
      "Epoch 42, Loss: 1.0941563487052917\n",
      "Epoch 43, Loss: 1.0924857079982757\n",
      "Epoch 44, Loss: 1.0898677051067351\n",
      "Epoch 45, Loss: 1.0862329602241516\n",
      "Epoch 46, Loss: 1.0866710484027862\n",
      "Epoch 47, Loss: 1.0747728645801544\n",
      "Epoch 48, Loss: 1.0693287014961244\n",
      "Epoch 49, Loss: 1.0630201876163483\n",
      "Epoch 50, Loss: 1.0415774583816528\n",
      "Epoch 51, Loss: 1.0312700718641281\n",
      "Epoch 52, Loss: 1.0217370599508286\n",
      "Epoch 53, Loss: 1.0178070217370987\n",
      "Epoch 54, Loss: 1.014534342288971\n",
      "Epoch 55, Loss: 1.006101331114769\n",
      "Epoch 56, Loss: 0.9943640142679214\n",
      "Epoch 57, Loss: 0.9922737002372741\n",
      "Epoch 58, Loss: 0.9940563291311264\n",
      "Epoch 59, Loss: 0.9900799930095673\n",
      "Epoch 60, Loss: 0.9808339476585388\n",
      "Epoch 61, Loss: 0.9828118026256562\n",
      "Epoch 62, Loss: 0.9747046381235123\n",
      "Epoch 63, Loss: 0.9739022970199585\n",
      "Epoch 64, Loss: 0.9747317016124726\n",
      "Epoch 65, Loss: 0.9701646625995636\n",
      "Epoch 66, Loss: 0.9713291317224503\n",
      "Epoch 67, Loss: 0.9707100957632064\n",
      "Epoch 68, Loss: 0.9661324560642243\n",
      "Epoch 69, Loss: 0.9669962972402573\n",
      "Epoch 70, Loss: 0.9573699504137039\n",
      "Epoch 71, Loss: 0.9540591269731522\n",
      "Epoch 72, Loss: 0.9575082153081894\n",
      "Epoch 73, Loss: 0.9559884369373322\n",
      "Epoch 74, Loss: 0.9583059221506118\n",
      "Epoch 75, Loss: 0.9580178648233414\n",
      "Epoch 76, Loss: 0.955720740556717\n",
      "Epoch 77, Loss: 0.9502230316400528\n",
      "Epoch 78, Loss: 0.95035440325737\n",
      "Epoch 79, Loss: 0.9410625874996186\n",
      "Epoch 80, Loss: 0.9412740021944046\n",
      "Epoch 81, Loss: 0.9395284235477448\n",
      "Epoch 82, Loss: 0.9413594692945481\n",
      "Epoch 83, Loss: 0.9353771686553956\n",
      "Epoch 84, Loss: 0.9365015745162963\n",
      "Epoch 85, Loss: 0.9348753839731216\n",
      "Epoch 86, Loss: 0.9304850250482559\n",
      "Epoch 87, Loss: 0.9213666260242462\n",
      "Epoch 88, Loss: 0.9228907018899918\n",
      "Epoch 89, Loss: 0.9277512758970261\n",
      "Epoch 90, Loss: 0.9164663344621659\n",
      "Epoch 91, Loss: 0.9209275931119919\n",
      "Epoch 92, Loss: 0.9189094871282577\n",
      "Epoch 93, Loss: 0.918083855509758\n",
      "Epoch 94, Loss: 0.9164599448442459\n",
      "Epoch 95, Loss: 0.9116052836179733\n",
      "Epoch 96, Loss: 0.9065548866987229\n",
      "Epoch 97, Loss: 0.9035005182027817\n",
      "Epoch 98, Loss: 0.8956162959337235\n",
      "Epoch 99, Loss: 0.9021565020084381\n",
      "Epoch 100, Loss: 0.8981146305799484\n",
      "Epoch 101, Loss: 0.8921885132789612\n",
      "Epoch 102, Loss: 0.8896410405635834\n",
      "Epoch 103, Loss: 0.8974898010492325\n",
      "Epoch 104, Loss: 0.9002277076244354\n",
      "Epoch 105, Loss: 0.9001905649900437\n",
      "Epoch 106, Loss: 0.9005080252885819\n",
      "Epoch 107, Loss: 0.8997367680072784\n",
      "Epoch 108, Loss: 0.8972928166389466\n",
      "Epoch 109, Loss: 0.8933747380971908\n",
      "Epoch 110, Loss: 0.8892585694789886\n",
      "Epoch 111, Loss: 0.8901989787817002\n",
      "Epoch 112, Loss: 0.8891234248876572\n",
      "Epoch 113, Loss: 0.8842635780572892\n",
      "Epoch 114, Loss: 0.8842893838882446\n",
      "Epoch 115, Loss: 0.8786571621894836\n",
      "Epoch 116, Loss: 0.8760920733213424\n",
      "Epoch 117, Loss: 0.87239670753479\n",
      "Epoch 118, Loss: 0.8718181699514389\n",
      "Epoch 119, Loss: 0.8693789958953857\n",
      "Epoch 120, Loss: 0.8711642861366272\n",
      "Epoch 121, Loss: 0.868125531077385\n",
      "Epoch 122, Loss: 0.8641453236341476\n",
      "Epoch 123, Loss: 0.8631051421165467\n",
      "Epoch 124, Loss: 0.8654848486185074\n",
      "Epoch 125, Loss: 0.859330826997757\n",
      "Epoch 126, Loss: 0.8597669124603271\n",
      "Epoch 127, Loss: 0.8600826919078827\n",
      "Epoch 128, Loss: 0.8616881012916565\n",
      "Epoch 129, Loss: 0.8567732155323029\n",
      "Epoch 130, Loss: 0.8595646232366562\n",
      "Epoch 131, Loss: 0.8585223585367203\n",
      "Epoch 132, Loss: 0.8582138806581497\n",
      "Epoch 133, Loss: 0.8540401846170426\n",
      "Epoch 134, Loss: 0.8593885064125061\n",
      "Epoch 135, Loss: 0.8628985583782196\n",
      "Epoch 136, Loss: 0.8603149741888046\n",
      "Epoch 137, Loss: 0.8574399679899216\n",
      "Epoch 138, Loss: 0.8588517874479293\n",
      "Epoch 139, Loss: 0.8543940871953964\n",
      "Epoch 140, Loss: 0.8571585804224015\n",
      "Epoch 141, Loss: 0.8582460016012192\n",
      "Epoch 142, Loss: 0.8624135792255402\n",
      "Epoch 143, Loss: 0.8556816846132278\n",
      "Epoch 144, Loss: 0.85759237408638\n",
      "Epoch 145, Loss: 0.8540219128131866\n",
      "Epoch 146, Loss: 0.8533828318119049\n",
      "Epoch 147, Loss: 0.847538685798645\n",
      "Epoch 148, Loss: 0.8485285192728043\n",
      "Epoch 149, Loss: 0.8465426415205002\n",
      "Epoch 150, Loss: 0.8428898453712463\n",
      "Epoch 151, Loss: 0.8467262804508209\n",
      "Epoch 152, Loss: 0.8426447927951812\n",
      "Epoch 153, Loss: 0.8420263290405273\n",
      "Epoch 154, Loss: 0.8444762855768204\n",
      "Epoch 155, Loss: 0.8405295222997665\n",
      "Epoch 156, Loss: 0.838955307006836\n",
      "Epoch 157, Loss: 0.8385525941848755\n",
      "Epoch 158, Loss: 0.8374472677707672\n",
      "Epoch 159, Loss: 0.8358275026082993\n",
      "Epoch 160, Loss: 0.8357230365276337\n",
      "Epoch 161, Loss: 0.8304184168577194\n",
      "Epoch 162, Loss: 0.8270914822816848\n",
      "Epoch 163, Loss: 0.8274634182453156\n",
      "Epoch 164, Loss: 0.8314208686351776\n",
      "Epoch 165, Loss: 0.8297792762517929\n",
      "Epoch 166, Loss: 0.8290178120136261\n",
      "Epoch 167, Loss: 0.8322608262300492\n",
      "Epoch 168, Loss: 0.83460932970047\n",
      "Epoch 169, Loss: 0.8325388997793197\n",
      "Epoch 170, Loss: 0.833047342300415\n",
      "Epoch 171, Loss: 0.8281250059604645\n",
      "Epoch 172, Loss: 0.8271069705486298\n",
      "Epoch 173, Loss: 0.8328681200742721\n",
      "Epoch 174, Loss: 0.8317624002695083\n",
      "Epoch 175, Loss: 0.8332825243473053\n",
      "Epoch 176, Loss: 0.8300054967403412\n",
      "Epoch 177, Loss: 0.8282582819461822\n",
      "Epoch 178, Loss: 0.8260531842708587\n",
      "Epoch 179, Loss: 0.8264467597007752\n",
      "Epoch 180, Loss: 0.8268890231847763\n",
      "Epoch 181, Loss: 0.8282247215509415\n",
      "Epoch 182, Loss: 0.8271589547395706\n",
      "Epoch 183, Loss: 0.8252597063779831\n",
      "Epoch 184, Loss: 0.8298681259155274\n",
      "Epoch 185, Loss: 0.8247562229633332\n",
      "Epoch 186, Loss: 0.8177775591611862\n",
      "Epoch 187, Loss: 0.8148995131254196\n",
      "Epoch 188, Loss: 0.8122023642063141\n",
      "Epoch 189, Loss: 0.8131692349910736\n",
      "Epoch 190, Loss: 0.8136028915643692\n",
      "Epoch 191, Loss: 0.814748564362526\n",
      "Epoch 192, Loss: 0.8192610055208206\n",
      "Epoch 193, Loss: 0.8168275684118271\n",
      "Epoch 194, Loss: 0.8192399859428405\n",
      "Epoch 195, Loss: 0.820726352930069\n",
      "Epoch 196, Loss: 0.8185981214046478\n",
      "Epoch 197, Loss: 0.8172110825777054\n",
      "Epoch 198, Loss: 0.8143600821495056\n",
      "Epoch 199, Loss: 0.8175486743450164\n",
      "Epoch 200, Loss: 0.8137531965970993\n"
     ]
    }
   ],
   "source": [
    "n_s = 2000\n",
    "max_seq_length = 128\n",
    "# num_epochs = 10\n",
    "num_epochs = 200\n",
    "batch_size = 100\n",
    "device = 'cuda:3'\n",
    "model.to(device)\n",
    "model.train()\n",
    "inputs_list, mask_list = get_training_sample(disease_db, disease_dict, node_embedding, n_s)\n",
    "inputs1 = inputs_list[0].to(device)\n",
    "inputs2 = inputs_list[1].to(device)\n",
    "masks1 = mask_list[0].to(device)\n",
    "masks2 = mask_list[0].to(device)\n",
    "\n",
    "\n",
    "num_batches = n_s // batch_size + (1 if n_s % batch_size != 0 else 0)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    total_steps = 0\n",
    "    \n",
    "    for batch_idx in range(num_batches):\n",
    "        start_idx = batch_idx * batch_size\n",
    "        end_idx = min(start_idx + batch_size, n_s)\n",
    "        \n",
    "        inputs1_batch = inputs1[start_idx:end_idx]\n",
    "        inputs2_batch = inputs2[start_idx:end_idx]\n",
    "        mask1_batch = masks1[start_idx:end_idx]\n",
    "        mask1_batch = mask1_batch.float()\n",
    "        mask2_batch = masks2[start_idx:end_idx]\n",
    "        mask2_batch = mask2_batch.float()\n",
    "        cls_embedding1, emb1 = model(inputs1_batch, mask1_batch)\n",
    "        cls_embedding2, emb2 = model(inputs2_batch, mask2_batch)\n",
    "        \n",
    "        labels = torch.tensor([1.0 if i == j else 0.0 for i in range(len(inputs1_batch)) for j in range(len(inputs2_batch))]).to(device).view(inputs1_batch.size(0), inputs2_batch.size(0))\n",
    "        \n",
    "        loss = info_nce_loss(cls_embedding1, cls_embedding2)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        total_steps += 1\n",
    "    \n",
    "    print(f'Epoch {epoch + 1}, Loss: {total_loss / total_steps}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "da469bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model.to('cpu')\n",
    "torch.save(model.state_dict(), './transformer_encoder_infoNCE_test.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "468ac90a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (PhenoDP)",
   "language": "python",
   "name": "phenodp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
